<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="es"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>HostDirectives.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">TFG</a> &gt; <a href="index.source.html" class="el_package">crawler</a> &gt; <span class="el_source">HostDirectives.java</span></div><h1>HostDirectives.java</h1><pre class="source lang-java linenums">/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the &quot;License&quot;); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package crawler;

import java.util.Set;
import java.util.TreeSet;

/**
 * @author Yasser Ganjisaffar
 */
public class HostDirectives {
    // If we fetched the directives for this host more than
    // 24 hours, we have to re-fetch it.
    private static final long EXPIRATION_DELAY = 24 * 60 * 1000L;

    public static final int ALLOWED = 1;
    public static final int DISALLOWED = 2;
    public static final int UNDEFINED = 3;

    /** A list of rule sets, sorted on match with the configured user agent */
    private Set&lt;UserAgentDirectives&gt; rules;

    private final long timeFetched;
    private long timeLastAccessed;
    private RobotstxtConfig config;
    private String userAgent;

<span class="nc" id="L43">    public HostDirectives(RobotstxtConfig configuration) {</span>
<span class="nc" id="L44">        timeFetched = System.currentTimeMillis();</span>
<span class="nc" id="L45">        config = configuration;</span>
<span class="nc" id="L46">        userAgent = config.getUserAgentName().toLowerCase();</span>
<span class="nc" id="L47">        rules = new TreeSet&lt;UserAgentDirectives&gt;(</span>
            new UserAgentDirectives.UserAgentComparator(userAgent));
<span class="nc" id="L49">    }</span>

    public boolean needsRefetch() {
<span class="nc bnc" id="L52" title="All 2 branches missed.">        return ((System.currentTimeMillis() - timeFetched) &gt; EXPIRATION_DELAY);</span>
    }

    /**
     * Check if the host directives allows visiting path.
     *
     * @param path The path to check
     * @return True if the path is not disallowed, false if it is
     */
    public boolean allows(String path) {
<span class="nc bnc" id="L62" title="All 2 branches missed.">        return checkAccess(path) != DISALLOWED;</span>
    }

    /**
     * Change the user agent string used to crawl after initialization. This will
     * reorder (recreate) the list of user agent directives for this host.
     *
     * @param userAgent The new user agent to use.
     */
    public void setUserAgent(String userAgent) {
<span class="nc" id="L72">        this.userAgent = userAgent.toLowerCase();</span>

        // Re-order the set
<span class="nc" id="L75">        Set&lt;UserAgentDirectives&gt; replace = new TreeSet&lt;UserAgentDirectives&gt;(</span>
            new UserAgentDirectives.UserAgentComparator(this.userAgent));
<span class="nc" id="L77">        replace.addAll(rules);</span>
<span class="nc" id="L78">        rules = replace;</span>
<span class="nc" id="L79">    }</span>

    /**
     * Check if the host directives explicitly disallow visiting path.
     *
     * @param path The path to check
     * @return True if the path is explicity disallowed, false otherwise
     */
    public boolean disallows(String path) {
<span class="nc bnc" id="L88" title="All 2 branches missed.">        return checkAccess(path) == DISALLOWED;</span>
    }

    /**
     * Check if any of the rules say anything about the specified path
     *
     * @param path The path to check
     * @return One of ALLOWED, DISALLOWED or UNDEFINED
     */
    public int checkAccess(String path) {
<span class="nc" id="L98">        timeLastAccessed = System.currentTimeMillis();</span>
<span class="nc" id="L99">        int result = UNDEFINED;</span>
<span class="nc" id="L100">        String myUA = config.getUserAgentName();</span>
<span class="nc" id="L101">        boolean ignoreUADisc = config.getIgnoreUADiscrimination();</span>

        // When checking rules, the list of rules is already ordered based on the
        // match of the user-agent of the clause with the user-agent of the crawler.
        // The most specific match should come first.
        //
        // Only the most specific match is obeyed, unless ignoreUADiscrimination is
        // enabled. In that case, any matching non-wildcard clause that explicitly
        // disallows the path is obeyed. If no such rule exists and any UA in the list
        // is allowed access, that rule is obeyed.
<span class="nc bnc" id="L111" title="All 2 branches missed.">        for (UserAgentDirectives ua : rules) {</span>
<span class="nc" id="L112">            int score = ua.match(myUA);</span>

            // If ignoreUADisc is disabled and the current UA doesn't match,
            // the rest will not match so we are done here.
<span class="nc bnc" id="L116" title="All 4 branches missed.">            if (score == 0 &amp;&amp; !ignoreUADisc) {</span>
<span class="nc" id="L117">                break;</span>
            }

            // Match the rule to the path
<span class="nc" id="L121">            result = ua.checkAccess(path, userAgent);</span>

            // If the result is ALLOWED or UNDEFINED, or if
            // this is a wildcard rule and ignoreUADisc is disabled,
            // this is the final verdict.
<span class="nc bnc" id="L126" title="All 6 branches missed.">            if (result != DISALLOWED || (!ua.isWildcard() || !ignoreUADisc)) {</span>
<span class="nc" id="L127">                break;</span>
            }

            // This is a wildcard rule that disallows access. The verdict is stored,
            // but the other rules will also be checked to see if any specific UA is allowed
            // access to this path. If so, that positive UA discrimination is ignored
            // and we crawl the page anyway.
<span class="nc" id="L134">        }</span>
<span class="nc" id="L135">        return result;</span>
    }

    /**
     * Store set of directives
     *
     * @param directives The set of directives to add to this host
     */
    public void addDirectives(UserAgentDirectives directives) {
<span class="nc" id="L144">        rules.add(directives);</span>
<span class="nc" id="L145">    }</span>

    public long getLastAccessTime() {
<span class="nc" id="L148">        return timeLastAccessed;</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.9.201702052155</span></div></body></html>